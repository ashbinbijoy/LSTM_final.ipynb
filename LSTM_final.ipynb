{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashbinbijoy/LSTM_final.ipynb/blob/main/LSTM_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXeEB-Aavwgk",
        "outputId": "65a69b9e-d968-4b1e-ca18-89b3b196e682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2027 - loss: 1.6102\n",
            "Epoch 2/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2315 - loss: 1.6050\n",
            "Epoch 3/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2704 - loss: 1.5948\n",
            "Epoch 4/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2624 - loss: 1.5878\n",
            "Epoch 5/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2765 - loss: 1.5817\n",
            "Epoch 6/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3036 - loss: 1.5669\n",
            "Epoch 7/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3143 - loss: 1.5534\n",
            "Epoch 8/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3228 - loss: 1.5584\n",
            "Epoch 9/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3561 - loss: 1.5235\n",
            "Epoch 10/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3071 - loss: 1.5401\n",
            "Epoch 11/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3475 - loss: 1.5166\n",
            "Epoch 12/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3572 - loss: 1.5005\n",
            "Epoch 13/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3850 - loss: 1.4928\n",
            "Epoch 14/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3482 - loss: 1.4921\n",
            "Epoch 15/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3694 - loss: 1.4704\n",
            "Epoch 16/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3756 - loss: 1.4461\n",
            "Epoch 17/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3884 - loss: 1.4392\n",
            "Epoch 18/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4013 - loss: 1.4373\n",
            "Epoch 19/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4004 - loss: 1.4192\n",
            "Epoch 20/20\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4094 - loss: 1.4177\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "LSTM Performance Metrics:\n",
            "Train Accuracy: 0.44\n",
            "Test Accuracy: 0.19\n",
            "Overall Accuracy: 0.19\n",
            "Precision: 0.20\n",
            "Recall: 0.19\n",
            "F1-Score: 0.19\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Load data\n",
        "X_train = np.loadtxt('/content/driver_activity_train.csv', delimiter=',', skiprows=1, usecols=range(10))\n",
        "y_train = np.loadtxt('/content/driver_activity_train.csv', delimiter=',', skiprows=1, usecols=10, dtype=str)\n",
        "X_test = np.loadtxt('/content/driver_activity_test.csv', delimiter=',', skiprows=1, usecols=range(10))\n",
        "y_test = np.loadtxt('/content/driver_activity_test.csv', delimiter=',', skiprows=1, usecols=10, dtype=str)\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)\n",
        "y_train_onehot = to_categorical(y_train_encoded)\n",
        "y_test_onehot = to_categorical(y_test_encoded)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape data for LSTM (samples, timesteps, features)\n",
        "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(1, X_train_scaled.shape[2])),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train_scaled, y_train_onehot, epochs=20, batch_size=16, verbose=1)\n",
        "\n",
        "# Predict on test data\n",
        "y_train_pred = np.argmax(model.predict(X_train_scaled), axis=1)\n",
        "y_test_pred = np.argmax(model.predict(X_test_scaled), axis=1)\n",
        "\n",
        "# Compute Metrics\n",
        "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "overall_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
        "precision = precision_score(y_test_encoded, y_test_pred, average='weighted', zero_division=1)\n",
        "recall = recall_score(y_test_encoded, y_test_pred, average='weighted', zero_division=1)\n",
        "f1 = f1_score(y_test_encoded, y_test_pred, average='weighted', zero_division=1)\n",
        "\n",
        "# Print Performance Metrics\n",
        "print(\"LSTM Performance Metrics:\")\n",
        "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ]
    }
  ]
}